# filtering to remove duplicates, blacklisted regions and sort before peak calling etc

# download of blacklisted regions 
#PBS -lwalltime=08:00:00
#PBS -lselect=1:ncpus=1:mem=900gb

wget https://github.com/Boyle-Lab/Blacklist/blob/master/lists/hg38-blacklist.v2.bed.gz
gunzip hg38-blacklist.v2.bed.gz

cp * $PBS_O_WORKDIR

# filtering and sorting code 
#PBS -lwalltime=08:00:00
#PBS -lselect=1:ncpus=200:mem=900gb
module load samtools
module load bedtools
module load picard
for file in $PBS_O_WORKDIR/*.sam
do
name=`basename $file .sam` 
samtools view -F 2308 -b -q 10 $PBS_O_WORKDIR/$name.sam > $name.bam
samtools sort -o $name.sort.bam -O 'bam' -T temp_$name $name.bam
picard MarkDuplicates REMOVE_DUPLICATES=TRUE I=$name.sort.bam O=$name.dedup.sort.bam M=$name.metrics.txt
bedtools intersect -v -abam $name.dedup.sort.bam -b '/rds/general/project/diantonio/live/tools/blacklisted_regions/hg38-blacklist.v2.bed' > $name.bl.dedup.sort.bam
samtools index $name.bl.dedup.sort.bam
rm $name.bam $name.sort.bam $name.dedup.sort.bam
done
cp * $PBS_O_WORKDIR

# de-duplication of reads did not work as well so an additional de-duplication job was needed to be submitted

#PBS -lwalltime=08:00:00
#PBS -lselect=1:ncpus=200:mem=900gb
module load samtools
module load bedtools
module load picard
for file in $PBS_O_WORKDIR/*.bl.dedup.sort.bam
do
name=`basename $file .bl.dedup.sort.bam`
picard MarkDuplicates REMOVE_DUPLICATES=TRUE I=$PBS_O_WORKDIR/$name.bl.dedup.sort.bam O=$name.dedup2.bl.dedup.sort.bam M=$name.dedup2.metrics.txt
samtools index $name.dedup2.bl.dedup.sort.bam
done

cp * $PBS_O_WORKDIR

# Check to see if fully deduplicated, see number of lines (less in deduplicated)
wc -l file.bam

# using samtools and flags
# value here should be 0 if no duplicates left
samtools view your_sample.bam | grep -c '2308\t'
